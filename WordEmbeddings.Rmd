---
title: "WordEmbeddingfile"
author: "DaisyZhan"
date: "6/16/2020"
output: html_document
---

```{r load packages, message=FALSE}
#load packages
library(plyr)
library(dplyr)
library(tidytext)
library(janeaustenr)
library(stringr)
library(ggplot2)
library(tm)
library(topicmodels)
library(data.table)
library(reshape2)
library(widyr)
library(vctrs)
library(irlba)
```

```{r}
#load data Encoding: move weird A symbols

short <- fread("CSVs/1550-1559.csv")
#short <- fread("CSVs/metadata-shorter.csv", encoding="UTF-8")

TCP_words <- short %>%
  unnest_tokens(word, booktext) %>%
  count(author,word,sort=TRUE)

#creates list of total amount of words in a func
total_words <- TCP_words %>%
  group_by(author) %>%
  summarize(total = sum(n))

TCP_words <- left_join(TCP_words, total_words)

names(TCP_words) <- c("author", "text", "n", "total")
TCP_words

```

```{r remove stop words}
custom_stop <- tibble(text = c("a","and","the","of","to","that", "in", "is", 
                               "it", "be", "but", "for", "you", "not", "in", 
                               "[unnumbered]","ã","thou","thy","hense","\210â", "doth", "1", "2",
                               "â","3","page","unnumbered", "10", "12", "6",
                               "s", "o", "m"))
data(stop_words)
#data(custom_stop)

tidy_TCP <- TCP_words %>%
  anti_join(custom_stop)

tidy_TCP
```

```{r count}
tidy_TCP %>%
  count(text, sort = TRUE) 

tidy_TCP
```

```{r convert short to a termdocumentmatrix}
## Use VectorSource before using Corpus
myCorpus <- Corpus(VectorSource(short$booktext))
short_tdm <- TermDocumentMatrix(myCorpus)
#inspect(short_tdm)
```

```{r skipgram probabilities}
#Select booktext
words <- tidy_TCP %>%
  select(c("text"))


#create context window with length 8

tidy_skipgrams <- words %>%
    unnest_tokens(ngram, text, token = "ngrams", n = 8) %>%
    mutate(ngramID = row_number()) %>% 
    tidyr::unite(skipgramID, ngramID) %>%
    unnest_tokens(word, ngram)

tidy_skipgrams
```

```{r calculate unigram probabilities}
unigram_probs <- words %>%
    unnest_tokens(word, text) %>%
    count(word, sort = TRUE) %>%
    mutate(p = n / sum(n))

unigram_probs
```

```{r calculate probabilities}
skipgram_probs <- tidy_skipgrams %>%
    pairwise_count(word, skipgramID, diag = TRUE, sort = TRUE) %>%
    mutate(p = n / sum(n))

skipgram_probs %>%
  filter( item1 == "this")
```

```{r}
#normalize probabilities
normalized_prob <- skipgram_probs %>%
    rename(word1 = item1, word2 = item2) %>%
    left_join(unigram_probs %>%
                  select(word1 = word, p1 = p),
              by = "word1") %>%
    left_join(unigram_probs %>%
                  select(word2 = word, p2 = p),
              by = "word2") %>%
    mutate(p_together = p / p1 / p2)

normalized_prob
```
```{r}
normalized_prob %>% 
    filter(word1 == "businesse") %>%
    arrange(-p_together)
```

```{r pmi_matrix}
pmi_matrix <- normalized_prob %>%
    mutate(pmi = log10(p_together)) %>%
    cast_sparse(word1, word2, pmi)
```

```{r Run SVD, eval=FALSE}
#remove missing data
pmi_matrix@x[is.na(pmi_matrix@x)] <- 0
#run SVD
pmi_svd <- irlba(pmi_matrix, 2, maxit = 500)
#next we output the word vectors:
word_vectors <- pmi_svd$u
rownames(word_vectors) <- rownames(pmi_matrix)
```

```{r search_synonyms}
search_synonyms <- function(word_vectors, selected_vector) {

    similarities <- word_vectors %*% selected_vector %>%
        tidy() %>%
        as_tibble() %>%
        rename(token = .rownames,
               similarity = unrowname.x.)

    similarities %>%
        arrange(-similarity)    
}
```

```{r top synonyms}
#look for top synonym for business
top_synonym <- search_synonyms(word_vectors,word_vectors["business",])
```
```{r}
top_synonym
```

```{r create 2d word embeddings model}
pmi_svd <- irlba(pmi_matrix, 2, maxit = 500)

#next we output the word vectors:
word_vectors <- pmi_svd$u
rownames(word_vectors) <- rownames(pmi_matrix)

#grab 100 words
forplot<-as.data.frame(word_vectors[200:300,])
forplot$word<-rownames(forplot)

#now plot
model <- ggplot(forplot, aes(x=V1, y=V2, label=word))+
  geom_text(aes(label=word),hjust=0, vjust=0, color="blue")+
  theme_minimal()+
  xlab("First Dimension Created by SVD")+
  ylab("Second Dimension Created by SVD") + 
  labs(title = "2D Word Embeddings Model by Singular Value Decomposition")

model
```

