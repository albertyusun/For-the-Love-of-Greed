---
title: "MainCode"
author: "Andrew"
date: "6/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r imports packages}
library(tidyverse)
library(plyr)
library(dplyr)
library(tidytext)
library(janeaustenr)
library(stringr)
library(ggplot2)
library(data.table)
library(reshape2)
library(tidyverse)
```

```{r import csv}
short <- read.csv("CSVs/metadata-shorter.csv", encoding="UTF-8")
#encoding removes the weird A symbols
#short <- read.csv("C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv")
#short <- fread('C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv')
```

# TidyText Section:

```{r create dataset that shows # occurences of words per book}
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
  mutate(book = substr(title, 1, 20)) 
short

#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
  unnest_tokens(word, booktext) %>%
  count(book, word, sort = TRUE)

#total_words: book, # total words in the book
total_words <- TCP_words %>%
#  group_by(author) %>%
  group_by(book) %>%
  summarize(total = sum(n))

#TCP_words: book, word, # of occurrences, total words 
TCP_words <- left_join(TCP_words, total_words)

TCP_words
```

```{r removes stop words}
custom_stop <- tibble(word = c("[unnumbered]","ã","thou","thy","hense","\210â", 
                               "doth", "1", "2", "â","3","page","unnumbered"))
data(stop_words)

tidy_TCP <- TCP_words %>%
  anti_join(stop_words) %>%
  anti_join((custom_stop))

tidy_TCP
```

```{r plot}
ggplot(TCP_words, aes(n/total, fill = book)) +
  geom_histogram(show.legend = FALSE, bins = 10) +
  facet_wrap(~book, ncol = 2, scales = "free_y") + 
  labs(x = "# words/Total", y = "Count")
```

# Topic Modelling Section: 

Topic Modeling Research:

- tidytext with topicmodeling: https://www.tidytextmining.com/topicmodeling.html

- Documentation of topic models: https://cran.r-project.org/web/packages/topicmodels/topicmodels.pdf

- Create DTM: https://towardsdatascience.com/beginners-guide-to-lda-topic-modelling-with-r-e57a5a8e7a25

- Topic modeling with tidytext: https://www.youtube.com/watch?v=evTuL-RcRpc


```{r import stm and quanteda}
library(stm)
library(quanteda)
```
```{r create document-feature matrix/documenttermmatrix}
TCP_dfm <- tidy_TCP %>%
  count(book, word, sort = TRUE, wt = n) %>%
  cast_dfm(book, word, n)

topic_model <- stm(TCP_dfm, K = 5, init.type = "Spectral")
```
```{r create summary of the topic model}
summary(topic_model)
```




```{ convert short to a termdocumentmatrix}
## Use VectorSource before using Corpus
short_Corpus <- Corpus(VectorSource(short$booktext))
short_tdm <- TermDocumentMatrix(myCorpus)
inspect(short_tdm)
```
```{ create LDA topic model object of short_tdm}
short_lda <- LDA(short_tdm, k = 2, control = list(seed = 1234))
short_lda
```
```{ create tidy object with topics in short_lda}
short_topics <- tidy(short_lda, matrix = "beta")
short_topics
```

```{}
top_terms <- short_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered()
```



