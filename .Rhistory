<<<<<<< HEAD
#load packages
=======
library(ggplot2)
library(data.table)
library(reshape2)
library(tidyverse)
short <- read.csv("CSVs/metadata-shorter.csv", encoding="UTF-8")
#encoding removes the weird A symbols
#short <- read.csv("C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv")
#short <- fread('C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv')
short <- read.csv("CSVs/metadata-shorter.csv", encoding="UTF-8")
#encoding removes the weird A symbols
#short <- read.csv("C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv")
#short <- fread('C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv')
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
count(book, word, sort = TRUE)
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
count(book, word)
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
count(word, sort = TRUE)
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
dplyr::count(word, sort = TRUE)
#total_words: book, # total words in the book
total_words <- TCP_words %>%
#  group_by(author) %>%
group_by(book) %>%
summarize(total = sum(n))
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
dplyr::count(book, word, sort = TRUE)
#total_words: book, # total words in the book
total_words <- TCP_words %>%
#  group_by(author) %>%
group_by(book) %>%
summarize(total = sum(n))
#TCP_words: book, word, # of occurrences, total words
TCP_words <- left_join(TCP_words, total_words)
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
dplyr::count(book, word, sort = TRUE)
TCP_words
#total_words: book, # total words in the book
total_words <- TCP_words %>%
#  group_by(author) %>%
group_by(book) %>%
summarize(total = sum(n))
#TCP_words: book, word, # of occurrences, total words
TCP_words <- left_join(TCP_words, total_words)
total_words
TCP_words
View(AssociatedPress)
rm(list = ls(all.names = TRUE))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(plyr)
library(dplyr)
library(tidytext)
library(janeaustenr)
library(stringr)
library(ggplot2)
library(data.table)
library(reshape2)
library(tidyverse)
short <- read.csv("CSVs/metadata-shorter.csv", encoding="UTF-8")
#encoding removes the weird A symbols
#short <- read.csv("C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv")
#short <- fread('C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv')
knitr::opts_chunk$set(echo = TRUE)
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
library(tidyverse)
library(dplyr)
library(plyr)
library(tidytext)
library(janeaustenr)
library(stringr)
library(ggplot2)
library(data.table)
library(reshape2)
library(tidyverse)
>>>>>>> 1b7219a8aa3ffe027c4224bdab57eef9f8c6044a
library(plyr)
library(dplyr)
library(tidytext)
library(janeaustenr)
library(stringr)
library(ggplot2)
<<<<<<< HEAD
library(tm)
library(topicmodels)
library(data.table)
library(reshape2)
setwd("~/Desktop/Git/For-the-Love-of-Greed2")
#load packages
library(plyr)
=======
library(data.table)
library(reshape2)
library(tidyverse)
short <- read.csv("CSVs/metadata-shorter.csv", encoding="UTF-8")
#encoding removes the weird A symbols
#short <- read.csv("C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv")
#short <- fread('C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv')
library(tidyverse)
library(tidytext)
library(janeaustenr)
library(stringr)
library(data.table)
library(reshape2)
short <- read.csv("CSVs/metadata-shorter.csv", encoding="UTF-8")
#encoding removes the weird A symbols
#short <- read.csv("C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv")
#short <- fread('C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv')
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
library(janeaustenr)
library(stringr)
library(data.table)
library(reshape2)
short <- read.csv("CSVs/metadata-shorter.csv", encoding="UTF-8")
#encoding removes the weird A symbols
#short <- read.csv("C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv")
#short <- fread('C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv')
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
dplyr::count(book, word, sort = TRUE)
TCP_words
#total_words: book, # total words in the book
total_words <- TCP_words %>%
#  group_by(author) %>%
group_by(book) %>%
summarize(total = sum(n))
total_words
#TCP_words: book, word, # of occurrences, total words
TCP_words <- left_join(TCP_words, total_words)
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
count(book, word, sort = TRUE)
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
dplyr::count(book, word, sort = TRUE)
TCP_words
#total_words: book, # total words in the book
total_words <- TCP_words %>%
#  group_by(author) %>%
group_by(book) %>%
summarize(total = sum(n))
total_words
#TCP_words: book, word, # of occurrences, total words
TCP_words <- left_join(TCP_words, total_words)
library(dplyr)
library(tidytext)
library(janeaustenr)
library(stringr)
library(data.table)
library(reshape2)
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
dplyr::count(book, word, sort = TRUE)
TCP_words
#total_words: book, # total words in the book
total_words <- TCP_words %>%
#  group_by(author) %>%
group_by(book) %>%
summarize(total = sum(n))
total_words
#TCP_words: book, word, # of occurrences, total words
TCP_words <- left_join(TCP_words, total_words)
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
count(book, word, sort = TRUE)
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
dplyr::count(book, word, sort = TRUE)
TCP_words
#total_words: book, # total words in the book
total_words <- TCP_words %>%
#  group_by(author) %>%
group_by(book) %>%
summarize(total = sum(n))
total_words
#TCP_words: book, word, # of occurrences, total words
TCP_words <- left_join(TCP_words, total_words)
library(tidyverse)
library(plyr)
library(dplyr)
library(tidytext)
library(janeaustenr)
library(stringr)
library(ggplot2)
library(data.table)
library(reshape2)
library(tidyverse)
short <- read.csv("CSVs/metadata-shorter.csv", encoding="UTF-8")
#encoding removes the weird A symbols
#short <- read.csv("C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv")
#short <- fread('C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv')
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
dplyr::count(book, word, sort = TRUE)
TCP_words
#total_words: book, # total words in the book
total_words <- TCP_words %>%
#  group_by(author) %>%
group_by(book) %>%
summarize(total = sum(n))
total_words
#TCP_words: book, word, # of occurrences, total words
TCP_words <- left_join(TCP_words, total_words)
TCP_words
total_words <- TCP_words %>%
#  group_by(author) %>%
group_by(book)
total_words <- TCP_words %>%
#  group_by(author) %>%
group_by(book)
total_words
total_words <- TCP_words %>%
#  group_by(author) %>%
group_by(book)
total_words
total_words <- TCP_words %>%
#  group_by(author) %>%
group_by(book)
total_words
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
dplyr::count(book, word, sort = TRUE)
TCP_words
#total_words: book, # total words in the book
total_words <- TCP_words %>%
#  group_by(author) %>%
group_by(book)
total_words
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
dplyr::count(book, word, sort = TRUE)
TCP_words
#total_words: book, # total words in the book
total_words <- TCP_words %>%
#  group_by(author) %>%
dplyr::group_by(book)
total_words
total_words <- TCP_words %>%
#  group_by(author) %>%
dplyr::group_by(book) %>%
summarize(total = sum(n))
total_words
total_words <- TCP_words %>%
#  group_by(author) %>%
dplyr::group_by(book) %>%
summarize(total = sum(n))
total_words
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
dplyr::count(book, word, sort = TRUE)
TCP_words
#total_words: book, # total words in the book
total_words <- TCP_words %>%
#  group_by(author) %>%
dplyr::group_by(book) %>%
summarize(total = sum(n))
total_words
#TCP_words: book, word, # of occurrences, total words
TCP_words <- left_join(TCP_words, total_words)
TCP_words %>%
#  group_by(author) %>%
dplyr::group_by(book) %>%
summarize(total = sum(n))
TCP_words %>%
dplyr::group_by(book) %>%
summarize(total = sum(n))
TCP_words %>%
dplyr::group_by(book)
TCP_words %>%
group_by(book)
TCP_words %>%
group_by(book)
TCP_words
TCP_words %>%
group_by(book)
TCP_words %>%
dplyr::group_by(book) %>%
dplyr::summarize(total = sum(n))
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
dplyr::count(book, word, sort = TRUE)
TCP_words
#total_words: book, # total words in the book
TCP_words %>%
dplyr::group_by(book) %>%
dplyr::summarize(total = sum(n))
total_words
#TCP_words: book, word, # of occurrences, total words
TCP_words <- left_join(TCP_words, total_words)
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
dplyr::count(book, word, sort = TRUE)
TCP_words
#total_words: book, # total words in the book
total_words <- TCP_words %>%
dplyr::group_by(book) %>%
dplyr::summarize(total = sum(n))
#TCP_words: book, word, # of occurrences, total words
TCP_words <- left_join(TCP_words, total_words)
TCP_words
knitr::opts_chunk$set(echo = TRUE)
>>>>>>> 1b7219a8aa3ffe027c4224bdab57eef9f8c6044a
library(dplyr)
library(tidytext)
library(janeaustenr)
library(stringr)
library(ggplot2)
<<<<<<< HEAD
library(tm)
library(topicmodels)
library(data.table)
library(reshape2)
#load data Encoding: move weird A symbols
metadata <- read.csv("CSVs/1690-1700.csv",stringsAsFactors=FALSE, fileEncoding="latin1")
TCP_words <- metadata %>%
unnest_tokens(word, booktext) %>%
dplyr:: count(author,word,sort=TRUE)
#load data Encoding: move weird A symbols
metadata <- read.csv("CSVs/1690-1700.csv",stringsAsFactors=FALSE, fileEncoding="latin1")
TCP_words <- metadata %>%
unnest_tokens(word, booktext) %>%
dplyr:: count(author,word,sort=TRUE)
#load data Encoding: move weird A symbols
short <- read.csv("CSVs/metadata-shorter.csv", encoding="UTF-8")
=======
library(data.table)
library(reshape2)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidytext)
library(janeaustenr)
library(stringr)
library(ggplot2)
library(data.table)
library(reshape2)
short <- read.csv("CSVs/metadata-shorter.csv", encoding="UTF-8")
#encoding removes the weird A symbols
#short <- read.csv("C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv")
#short <- fread('C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv')
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
>>>>>>> 1b7219a8aa3ffe027c4224bdab57eef9f8c6044a
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
dplyr::count(book, word, sort = TRUE)
TCP_words
#total_words: book, # total words in the book
total_words <- TCP_words %>%
dplyr::group_by(book) %>%
dplyr::summarize(total = sum(n))
#TCP_words: book, word, # of occurrences, total words
TCP_words <- left_join(TCP_words, total_words)
TCP_words
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidytext)
library(janeaustenr)
library(stringr)
library(ggplot2)
library(data.table)
library(reshape2)
short <- read.csv("CSVs/metadata-shorter.csv", encoding="UTF-8")
#encoding removes the weird A symbols
#short <- read.csv("C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv")
#short <- fread('C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv')
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
count(book, word, sort = TRUE)
TCP_words
#total_words: book, # total words in the book
total_words <- TCP_words %>%
group_by(book) %>%
summarize(total = sum(n))
#TCP_words: book, word, # of occurrences, total words
TCP_words <- left_join(TCP_words, total_words)
TCP_words
<<<<<<< HEAD
custom_stop <- tibble(word = c("a","and","the","of","to","that", "in", "is",
"it", "be", "but", "for", "you", "not", "in",
"[unnumbered]","ã","thou","thy","hense","\210â", "doth", "1", "2",
"â","3","page","unnumbered"))
data(stop_words)
#data(custom_stop)
=======
custom_stop <- tibble(word = c("[unnumbered]","ã","thou","thy","hense","\210â",
"doth", "1", "2", "â","3","page","unnumbered"))
data(stop_words)
>>>>>>> 1b7219a8aa3ffe027c4224bdab57eef9f8c6044a
tidy_TCP <- TCP_words %>%
anti_join(stop_words) %>%
anti_join((custom_stop))
tidy_TCP
<<<<<<< HEAD
short_tdm
short_Corpus
tidy_TCP %>%
count(word, sort = TRUE)
short_Corpus <- Corpus(VectorSource(short$booktext))
short_tdm <- TermDocumentMatrix(myCorpus)
inspect(short_tdm)
install.packages("tmap")
short_Corpus <- Corpus(VectorSource(short$booktext))
short_tdm <- TermDocumentMatrix(myCorpus)
inspect(short_tdm)
knitr::opts_chunk$set(echo = TRUE)
myCorpus <- Corpus(VectorSource(short$booktext))
short_tdm <- TermDocumentMatrix(myCorpus)
inspect(short_tdm)
myCorpus <- Corpus(VectorSource(short$booktext))
short_tdm <- TermDocumentMatrix(myCorpus)
inspect(short_tdm)
tidy_skipgrams <- tidy_TCP %>%
unnest_tokens(ngram, text, token = "ngrams", n = 8) %>%
mutate(ngramID = row_number()) %>%
tidyr::unite(skipgramID, postID, ngramID) %>%
unnest_tokens(word, ngram)
cleantext <- tidy_TCP[:,2]
tidy_TCP %>%
select(booktext)
tidy_TCP %>%
select(word)
words <- tidy_TCP %>%
select(word)
tidy_skipgrams <- words %>%
unnest_tokens(ngram, text, token = "ngrams", n = 8) %>%
mutate(ngramID = row_number()) %>%
tidyr::unite(skipgramID, postID, ngramID) %>%
unnest_tokens(word, ngram)
words <- tidy_TCP %>%
select(c('word'))
tidy_skipgrams <- words %>%
unnest_tokens(ngram, text, token = "ngrams", n = 8) %>%
mutate(ngramID = row_number()) %>%
tidyr::unite(skipgramID, postID, ngramID) %>%
unnest_tokens(word, ngram)
wordID <- row.names(words)
#create context window with length 8
tidy_skipgrams <- words %>%
unnest_tokens(ngram, text, token = "ngrams", n = 8) %>%
mutate(ngramID = row_number()) %>%
tidyr::unite(skipgramID, ngramID) %>%
unnest_tokens(word, ngram)
unigram_probs <- words %>%
unnest_tokens(word, text) %>%
count(word, sort = TRUE) %>%
mutate(p = n / sum(n))
words
tidy_skipgrams <- words %>%
unnest_tokens(ngram, text, n = 8) %>%
mutate(ngramID = row_number()) %>%
tidyr::unite(skipgramID, ngramID) %>%
unnest_tokens(word, ngram)
skipgram_probs <- tidy_skipgrams %>%
pairwise_count(word, skipgramID, diag = TRUE, sort = TRUE) %>%
mutate(p = n / sum(n))}
skipgram_probs <- tidy_skipgrams %>%
pairwise_count(word, skipgramID, diag = TRUE, sort = TRUE) %>%
mutate(p = n / sum(n))
tidy_skipgrams <- words %>%
unnest_tokens(ngram, text) %>%
mutate(ngramID = row_number()) %>%
tidyr::unite(skipgramID, ngramID) %>%
unnest_tokens(word, ngram)
unnest_tokens(words, ngram)
unnest_tokens(word, ngrams)
unnest_tokens('words', ngram)
install.packages("widyr")
#load packages
library(plyr)
=======
ggplot(TCP_words, aes(n/total, fill = book)) +
geom_histogram(show.legend = FALSE, bins = 10) +
facet_wrap(~book, ncol = 2, scales = "free_y") +
labs(x = "# words/Total", y = "Count")
library(stm)
library(quanteda)
>>>>>>> 1b7219a8aa3ffe027c4224bdab57eef9f8c6044a
library(dplyr)
library(tidytext)
library(janeaustenr)
library(stringr)
library(ggplot2)
<<<<<<< HEAD
library(tm)
library(topicmodels)
library(data.table)
library(reshape2)
library(widyr)
yes
tidy_skipgrams <- words %>%
unnest_tokens(ngram, text, token = "ngrams", n = 8) %>%
mutate(ngramID = row_number()) %>%
tidyr::unite(skipgramID, ngramID) %>%
unnest_tokens(word, ngram)
words
strsplit(words, " ")[[1]]
strsplit(words, "\\s+")[[1]]
library(vctrs)
vec_is(words)
unigram_probs <- words %>%
unnest_tokens(word, text) %>%
count(word, sort = TRUE) %>%
mutate(p = n / sum(n))
=======
library(data.table)
library(reshape2)
library(stm)
library(quanteda)
summary(topic_model)
TCP_dfm <- tidy_TCP %>%
count(book, word, sort = TRUE, wt = n) %>%
cast_dfm(book, word, n)
topic_model <- stm(TCP_dfm, K = 3, init.type = "Spectral")
summary(topic_model)
td_beta <- tidy(topic_model)
td_beta %>%
group_by(topic) %>%
top_n(10) %>%
ungroup %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = topic)) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
coord_flip()
td_beta <- tidy(topic_model)
top_ten_model <- td_beta %>%
group_by(topic) %>%
top_n(10) %>%
ungroup %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = topic)) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
coord_flip()
top_ten_model
td_beta <- tidy(topic_model)
top_ten_model <- td_beta %>%
group_by(topic) %>%
top_n(10) %>%
ungroup %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = topic)) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
coord_flip()
>>>>>>> 1b7219a8aa3ffe027c4224bdab57eef9f8c6044a
