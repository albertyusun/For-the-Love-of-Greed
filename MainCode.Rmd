---
title: "MainCode"
author: "Andrew"
date: "6/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r imports packages}
library(dplyr)
library(tidytext)
library(janeaustenr)
library(stringr)
library(ggplot2)
library(tm)
library(topicmodels)
```

```{r import csv}
short <- read.csv("CSVs/metadata-shorter.csv", encoding="UTF-8")
#encoding removes the weird A symbols
```

```{r create dataset that counts words}
#use the first 9 texts for now because the last one is super long
TCP_words <- short %>%
  slice(1:9) %>%
  unnest_tokens(word, booktext) %>%
  count(author,word,sort=TRUE)

#creates list of total amount of words in a func
total_words <- TCP_words %>%
  group_by(author) %>%
  summarize(total = sum(n))

TCP_words <- left_join(TCP_words, total_words)

TCP_words
```

```{r removes words}
custom_stop <- tibble(word = c("a","and","the","of","to","that", "in", "is", 
                               "it", "be", "but", "for", "you", "not", "in", 
                               "[unnumbered]", ""))
#data(custom_stop)

tidy_TCP <- TCP_words %>%
  anti_join(custom_stop)

tidy_TCP
```

```{r count}
tidy_TCP %>%
  count(word, sort = TRUE) 
```

```{r plot}
ggplot(TCP_words, aes(n/total, fill = author)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.0009) +
  facet_wrap(~author, ncol = 2, scales = "free_y")
```
Topic Modelling Research:
tidytext with topicmodeling: https://www.tidytextmining.com/topicmodeling.html
Documentation of topic models: https://cran.r-project.org/web/packages/topicmodels/topicmodels.pdf

```{r}
## Use VectorSource before using Corpus
myCorpus <- Corpus(VectorSource(short$booktext))
tdm <- TermDocumentMatrix(myCorpus)
inspect(tdm)
```


```{r}
data("AssociatedPress")

AssociatedPress

```


