#encoding removes the weird A symbols
#short <- read.csv("C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv")
#short <- fread('C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv')
# stop the clock
proc.time() - ptm
g <- rnorm(100000)
h <- rep(NA, 100000)
# start the clock
ptm <- proc.time()
# look thru the vector, adding one
for(i in 1:100000){
h[i] <- g[i] + 1
}
#short <- read.csv("CSVs/metadata-shorter.csv", encoding="UTF-8")
short <- fread("CSVs/1550-1559.csv")
#encoding removes the weird A symbols
#short <- read.csv("C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv")
#short <- fread('C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv')
# stop the clock
proc.time() - ptm
g <- rnorm(100000)
h <- rep(NA, 100000)
# start the clock
ptm <- proc.time()
# look thru the vector, adding one
for(i in 1:100000){
h[i] <- g[i] + 1
}
#short <- read.csv("CSVs/metadata-shorter.csv", encoding="UTF-8")
short <- fread("CSVs/1550-1559.csv")
#encoding removes the weird A symbols
#short <- read.csv("C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv")
#short <- fread('C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv')
# stop the clock
proc.time() - ptm
#shorten titles to 20 char into a new variable called 'book'
short <- short %>%
mutate(book = substr(title, 1, 20))
short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
count(book, word, sort = TRUE)
TCP_words
#total_words: book, # total words in the book
total_words <- TCP_words %>%
group_by(book) %>%
summarize(total = sum(n))
#TCP_words: book, word, # of occurrences, total words
TCP_words <- left_join(TCP_words, total_words)
TCP_words
#shorten titles to 20 char into a new variable called 'book'
#short <- short %>%
mutate(book = substr(title, 1, 20))
#shorten titles to 20 char into a new variable called 'book'
#short <- short %>%
#  mutate(book = substr(title, 1, 20))
#short
#TCP_words: book, word, # of occurrences
TCP_words <- short %>%
unnest_tokens(word, booktext) %>%
count(book, word, sort = TRUE)
TCP_words
#total_words: book, # total words in the book
total_words <- TCP_words %>%
group_by(book) %>%
summarize(total = sum(n))
#TCP_words: book, word, # of occurrences, total words
TCP_words <- left_join(TCP_words, total_words)
TCP_words
custom_stop <- tibble(word = c("[unnumbered]","ã","thou","thy","hense","\210â",
"doth", "1", "2", "â","3","page","unnumbered"))
data(stop_words)
tidy_TCP <- TCP_words %>%
anti_join(stop_words) %>%
anti_join((custom_stop))
tidy_TCP
ggplot(TCP_words, aes(n/total, fill = book)) +
geom_histogram(show.legend = FALSE, bins = 10) +
facet_wrap(~book, ncol = 2, scales = "free_y") +
labs(x = "# words/Total", y = "Count")
TCP_dfm <- tidy_TCP %>%
count(book, word, sort = TRUE, wt = n) %>%
cast_dfm(book, word, n)
topic_model <- stm(TCP_dfm, K = 3, init.type = "Spectral")
summary(topic_model)
stm_summary <- plot(topic_model, type = c("summary"), n = 3)
stm_labels <- plot(topic_model, type = c("labels"))
stm_hist <- plot(topic_model, type = c("hist"))
stm_summary <- plot(topic_model, type = c("summary"), n = 3)
td_beta <- tidy(topic_model)
td_beta <- td_beta %>%
mutate(topic = factor(topic))
topic.labs <- c("Nobility", "Commerce", "Church")
names(topic.labs) <- c("1", "2", "3")
top_ten_model <- td_beta %>%
group_by(topic) %>%
top_n(10) %>%
ungroup %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = topic)) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free", ,
labeller = labeller(topic = topic.labs)) +
coord_flip() +
theme_gray(base_size = 23) +
labs(title = "Top 10 Words in our 3 LDA-Generated Topics",
x = "Word",
y = "Word-to-Topic Percentage") +
scale_y_continuous(labels = scales::percent) +
theme(axis.text.x = element_text(size = 15))
top_ten_model
TCP_dfm <- tidy_TCP %>%
count(book, word, sort = TRUE, wt = n) %>%
cast_dfm(book, word, n)
topic_model <- stm(TCP_dfm, K = 5, init.type = "Spectral")
summary(topic_model)
custom_stop <- tibble(word = c("[unnumbered]","ã","thou","thy","hense","\210â",
"doth", "1", "2", "â","3","page","unnumbered"))
data(stop_words)
tidy_TCP <- TCP_words %>%
anti_join(stop_words) %>%
anti_join((custom_stop))
tidy_TCP
library(dplyr)
library(ggplot2)
library(tidytext)
library(data.table)
#books <- read.csv("metasplit1.csv") # the first 500 books.
books <- fread("CSVs/1550-1559.csv") # the first 500 books.
book_words <- books %>%
unnest_tokens(word, booktext) %>%
count(title,word,sort=TRUE)
book_words
View(book_words)
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
distinct()
new_book_words
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
distinct()
new_book_words
select(new_book_words)
vignette("dplyr")
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
distinct()
new_book_words
stop_list <- new_book_words %>%
select() %>%
slice(1:20)
stop_list_1550 <- new_book_words %>%
select() %>%
slice(1:100)
stop_list_1550
stop_list_1550 <- new_book_words %>%
select() %>%
slice(1:100)
stop_list_1550
new_book_words %>%
select()
new_book_words
new_book_words %>%
select() %>%
slice(1:100)
stop_list_1550 <- new_book_words %>%
select(word) %>%
slice(1:100)
stop_list_1550 <- new_book_words %>%
select(word) %>%
slice(1:100)
stop_list_1550
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
distinct()
new_book_words
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
arrange(word)
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
arrange(-avg_freq)
distinct()
new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
arrange(-avg_freq)
new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
arrange(-avg_freq) %>%
distinct()
new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
#  arrange(-avg_freq) %>%
distinct()
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
#  arrange(-avg_freq) %>%
distinct()
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
arrange(-avg_freq) %>%
distinct()
new_book_words
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
distinct()
new_book_words
stop_list_1550 <- new_book_words %>%
select(word) %>%
slice(1:100)
stop_list_1550
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
distinct()
new_book_words
stop_list_1550 <- new_book_words %>%
slice(1:100)
stop_list_1550
new_book_words %>%
slice(1:100)
library(dplyr)
library(ggplot2)
library(tidytext)
library(data.table)
new_book_words %>%
slice(1)
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
distinct()
new_book_words
new_book_words <- new_book_words %>%
slice_head(1)
new_book_words
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
distinct()
new_book_words
new_book_words <- new_book_words %>%
dplyr::slice_head(1)
new_book_words
library(dplyr)
library(ggplot2)
library(tidytext)
library(data.table)
#books <- read.csv("metasplit1.csv") # the first 500 books.
books <- fread("CSVs/1550-1559.csv") # the first 500 books.
book_words <- books %>%
unnest_tokens(word, booktext) %>%
count(title,word,sort=TRUE)
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
distinct()
new_book_words
stop_list_1550 <- new_book_words %>%
dplyr::slice_head(1)
stop_list_1550
new_book_words %>%
dplyr::slice(1:2)
detach("package:S4Vectors")
detach("package:S4Vectors")
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
distinct() %>%
ungroup()
new_book_words
stop_list_1550 <- new_book_words %>%
dplyr::slice(1:2)
stop_list_1550
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
distinct() %>%
ungroup()
new_book_words
stop_list_1550 <- new_book_words %>%
:slice(1:100)
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
distinct() %>%
ungroup()
new_book_words
stop_list_1550 <- new_book_words %>%
slice(1:100)
stop_list_1550
vignette(dplyr)
vignette("dplyr)
vignette("dplyr")
vignette("dplyr")
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
distinct() %>%
ungroup()
new_book_words
stop_list_1550 <- new_book_words %>%
slice(1:100) %>%
filter(word!="god")
stop_list_1550
stop_list_1550 <- new_book_words %>%
slice(1:100) %>%
filter(word!=c("god"))
stop_list_1550 <- new_book_words %>%
slice(1:100) %>%
filter(word!=c("god"))
stop_list_1550
stop_list_1550 <- new_book_words %>%
slice(1:100) %>%
filter(word!=c("god", "before"))
stop_list_1550
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
distinct() %>%
ungroup()
new_book_words
stop_list_1550 <- new_book_words %>%
slice(1:100) %>%
filter(!word %in% c("god", "athenyans"))
stop_list_1550
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
distinct() %>%
ungroup()
new_book_words
stop_list_1550 <- new_book_words %>%
slice(1:100) %>%
filter(!word %in% c("christ","men","worlde","anni","regum","christe","nocht","king","sea","warre","grekes","cauled"))
stop_list_1550
new_book_words %>%
slice(1:200)
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
distinct() %>%
ungroup()
new_book_words
stop_list_1550 <- new_book_words %>%
slice(1:140) %>%
filter(!word %in% c("christ","men","worlde","anni","regum","christe","nocht","king","sea","warre","grekes","cauled","rome","certeyne","reigned","britayne","emperour","angli","angli","knovven","hadde"))
stop_list_1550
stop_list_1550
new_book_words <- book_words
new_book_words <- new_book_words %>%
group_by(title) %>%
mutate(book_size = sum(n)) %>%
ungroup() %>%
mutate(frequency = n / book_size) %>%
group_by(word) %>%
mutate(avg_freq = mean(frequency)) %>%
select(word, avg_freq) %>%
distinct() %>%
ungroup()
new_book_words
stop_list_1550 <- new_book_words %>%
slice(1:140) %>%
filter(!word %in% c("christ","men","worlde","anni","regum","christe","nocht","king","sea","warre","grekes","cauled","rome","certeyne","reigned","britayne","emperour","angli","angli","knovven","hadde"))
stop_list_1550
