---
title: "MainCode"
author: "Andrew"
date: "6/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r imports packages}
library(plyr)
library(dplyr)
library(tidytext)
library(janeaustenr)
library(stringr)
library(ggplot2)
library(tm)
library(topicmodels)
library(data.table)
library(reshape2)
```

```{r import csv}
short <- read.csv("CSVs/metadata-shorter.csv", encoding="UTF-8")
#encoding removes the weird A symbols
#short <- read.csv("C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv")
#short <- fread('C:\\Users\\andre\\Metadata\\MetaThird2\\metaThird2.csv')
```

# TidyText Section:

```{r create dataset that counts words}
#use the first 9 texts for now because the last one is super long
TCP_words <- short %>%
  unnest_tokens(word, booktext) %>%
  count(author,word,sort=TRUE)

#creates list of total amount of words in a func
total_words <- TCP_words %>%
  group_by(author) %>%
  summarize(total = sum(n))

TCP_words <- left_join(TCP_words, total_words)

TCP_words
```

```{r removes words}
custom_stop <- tibble(word = c("a","and","the","of","to","that", "in", "is", 
                               "it", "be", "but", "for", "you", "not", "in", 
                               "[unnumbered]","ã","thou","thy","hense","\210â", "doth", "1", "2",
                               "â","3","page","unnumbered"))
data(stop_words)
#data(custom_stop)

tidy_TCP <- TCP_words %>%
  anti_join(stop_words) %>%
  anti_join((custom_stop))

tidy_TCP
```

```{r count}
tidy_TCP %>%
  count(word, sort = TRUE) 
```

```{r plot}
ggplot(TCP_words, aes(n/total, fill = author)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.0009) +
  facet_wrap(~author, ncol = 2, scales = "free_y")
```

# Topic Modelling Section: 

Topic Modelling Research:

- tidytext with topicmodeling: https://www.tidytextmining.com/topicmodeling.html

- Documentation of topic models: https://cran.r-project.org/web/packages/topicmodels/topicmodels.pdf

- Create DTM: https://towardsdatascience.com/beginners-guide-to-lda-topic-modelling-with-r-e57a5a8e7a25
```{r convert short to a termdocumentmatrix}
## Use VectorSource before using Corpus
short_Corpus <- Corpus(VectorSource(short$booktext))
short_tdm <- TermDocumentMatrix(myCorpus)
inspect(short_tdm)
```
```{r create LDA topic model object of short_tdm}
short_lda <- LDA(short_tdm, k = 2, control = list(seed = 1234))
short_lda
```
```{r create tidy object with topics in short_lda}
short_topics <- tidy(short_lda, matrix = "beta")
short_topics
```

```{r}
top_terms <- short_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered()
```



